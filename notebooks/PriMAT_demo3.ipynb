{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PriMAT: Multi-animal tracking\n",
        "\n",
        "In this notebook, we want to demonstrate how to train a tracking model from a few hundred frames. We will train a model that is able to track lemurs and feeding boxes with labelled images which can be downloaded [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> Training Images / LemurBoxSep22 )."
      ],
      "metadata": {
        "id": "A0Atdc4Fr6C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "mY2JvaUBk8ai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da524ad8-362e-4a49-b6b2-fbe459768d83"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Dec 11 10:19:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_vCjKCgCCSw",
        "outputId": "cd97b761-e4c5-4360-a434-ec0af676ec73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 3,917 B in 1s (2,767 B/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package libmediainfo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install -y mediainfo libmediainfo\n",
        "\n",
        "# =========================\n",
        "# Colab: installation via pip (versions épinglées) + MediaInfo/pymediainfo\n",
        "# =========================\n",
        "import sys, subprocess\n",
        "\n",
        "def run(cmd):\n",
        "    print(\">>>\", cmd)\n",
        "    subprocess.check_call(cmd, shell=True)\n",
        "\n",
        "def pip_install(*pkgs):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-U\"]\n",
        "    cmd += list(pkgs)\n",
        "    print(\">>>\", \" \".join(cmd))\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "# 1) PIP et libs Python (tes versions)\n",
        "pip_install(\"pip==23.1\")\n",
        "pip_install(\n",
        "    \"numpy==1.20.0\",\n",
        "    \"Cython==0.29.*\",\n",
        "    \"matplotlib==3.5.*\",\n",
        "    \"pandas==1.4.*\",\n",
        "    \"Pillow==9.4.*\",\n",
        "    \"pycocotools==2.0.*\",\n",
        "    \"seaborn==0.12.*\",\n",
        "    \"torchmetrics==0.10.*\",\n",
        "    \"attrs==21.4.0\",\n",
        "    \"entrypoints==0.3\",\n",
        "    \"iprogress==0.4\",\n",
        "    \"joblib==1.3.1\",\n",
        "    \"pytz==2021.3\",\n",
        "    \"PyYAML==6.0\",\n",
        "    \"scikit-learn==1.3.0\",\n",
        "    \"threadpoolctl==3.1.0\",\n",
        ")\n",
        "\n",
        "# 2) PyTorch CPU-only (plus simple avec versions anciennes)\n",
        "run(\"pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\")\n",
        "\n",
        "# =========================\n",
        "# Vérifications rapides\n",
        "# =========================\n",
        "print(\"\\n=== Vérifications ===\")\n",
        "def check_imports():\n",
        "    import numpy as np\n",
        "    import torch, torchvision\n",
        "    import pandas as pd, matplotlib, PIL\n",
        "    import pycocotools, seaborn, pymediainfo, torchmetrics, sklearn\n",
        "    print(\"Python :\", sys.version)\n",
        "    print(\"NumPy :\", np.__version__)\n",
        "    print(\"Torch :\", torch.__version__, \"| Torchvision :\", torchvision.__version__)\n",
        "    print(\"Pandas:\", pd.__version__, \"| Matplotlib:\", matplotlib.__version__)\n",
        "    print(\"scikit-learn:\", sklearn.__version__)\n",
        "    print(\"Pillow:\", PIL.__version__, \"| seaborn:\", seaborn.__version__)\n",
        "    print(\"pycocotools OK:\", hasattr(pycocotools, \"__version__\"))\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "\n",
        "try:\n",
        "    check_imports()\n",
        "except Exception as e:\n",
        "    print(\"Erreur de vérification:\", e)\n"
      ],
      "metadata": {
        "id": "Q3JvFWy36wD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install yacs==0.1.8\n",
        "!pip install opencv-python\n",
        "!pip install progress==1.6\n",
        "!pip install scikit-learn==1.2.2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SrxawMA3lDGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hj9s06hC5_Yq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85bf622-967e-43e2-b82e-393bfd41584b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PriMAT-tracking'...\n",
            "remote: Enumerating objects: 8971, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 8971 (delta 0), reused 0 (delta 0), pack-reused 8968 (from 2)\u001b[K\n",
            "Receiving objects: 100% (8971/8971), 144.93 MiB | 14.19 MiB/s, done.\n",
            "Resolving deltas: 100% (1789/1789), done.\n",
            "Updating files: 100% (8972/8972), done.\n",
            "/content/PriMAT-tracking\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ecker-lab/PriMAT-tracking.git\n",
        "%cd PriMAT-tracking/\n",
        "!mkdir data\n",
        "!mkdir models\n",
        "!mkdir exp\n",
        "!mkdir videos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "### Extract data"
      ],
      "metadata": {
        "id": "AE-cGOn0x53f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to upload the folder with the data to the colab space on the left. I uploaded it as a tar file and extracted it into the folder \"data\". The only important thing is that after this step you have training material in the folder data."
      ],
      "metadata": {
        "id": "dRfHHdpsslRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WbTCdH-fx_WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip /content/PriMAT-tracking/data/LemurBoxSep22.zip >/dev/null\n"
      ],
      "metadata": {
        "id": "ix7jA_T4CL62"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run training script"
      ],
      "metadata": {
        "id": "2Z6s9wDSyA_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell you start the training.\n",
        "\n",
        "1.   Élément de liste\n",
        "2.   Élément de liste\n",
        "\n",
        "Before this you have to make sure a few things:\n",
        "- The data_cfg file has to point to the correct location of your data. Open it (it is in PriMAT-tracking/src/lib/cfg/lemur-box.json) and adapt the root (for me it is /content/PriMAT-tracking/data/ in colab).\n",
        "- Give your experiment a name (--exp_id) so that you can find the model afterwards in exp/mot/exp_id/."
      ],
      "metadata": {
        "id": "eZF9kulKs868"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd src\n",
        "python train.py mot --exp_id colab_test\\\n",
        "                    --load_model ''\\\n",
        "                    --num_epochs 10\\\n",
        "                    --lr_step 5\\\n",
        "                    --lr '1e-4'\\\n",
        "                    --data_cfg '/content/PriMAT-tracking/src/lib/cfg/lemur_box.json'\\\n",
        "                    --store_opt\\\n",
        "                    --arch hrnet_32\\\n",
        "                    --gpus 0\\\n",
        "                    --batch_size 2\\\n",
        "                    --seed 13\\\n",
        "                    --reid_cls_names lemur,box\\\n",
        "                    --val_intervals 10\\\n",
        "                    --save_all\n",
        "cd .."
      ],
      "metadata": {
        "id": "06vNX0r2EQFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7717f9-6c21-4d67-a091-f7ca843bf2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PriMAT-tracking/src/lib\n",
            "training chunk_sizes: [2]\n",
            "The output will be saved to  /content/PriMAT-tracking/src/lib/../../exp/mot/colab_test\n",
            "Setting up data...\n",
            "================================================================================\n",
            "dataset summary\n",
            "OrderedDict([('lemur_box_train', defaultdict(<class 'int'>, {0: 1361.0, 1: 1343.0}))])\n",
            "start index\n",
            "OrderedDict()\n",
            "================================================================================\n",
            "heads {'hm': 2, 'wh': 2, 'id': 128, 'reg': 2}\n",
            "Namespace(K=50, arch='hrnet_32', batch_size=2, buffered_iou=0, cat_spec_wh=False, chunk_sizes=[2], class_names=['lemur', 'box'], clsID4GC=0, conf_thres=0.02, data_cfg='/content/PriMAT-tracking/src/lib/cfg/lemur_box.json', data_dir='../local_datasets/', dataset='jde', debug_dir='/content/PriMAT-tracking/src/lib/../../exp/mot/colab_test/debug', debug_info=False, dense_wh=False, det_thres=0.7, double_kalman=False, down_ratio=4, exp_dir='/content/PriMAT-tracking/src/lib/../../exp/mot', exp_id='colab_test', f=None, gc_cls_names='walking,sitting,standing2legs,standing4legs,NiS', gc_dim=128, gc_lbl_cnts=False, gc_loss='CrEn', gc_with_roi=False, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 2, 'wh': 2, 'id': 128, 'reg': 2}, hide_data_time=False, hm_weight=1, id_inline=False, id_loss='ce', id_weight=1, input_h=608, input_video='../videos/MOT16-03.mp4', input_w=1088, line_thickness=1, load_id_model='', load_model='', load_tracking_model='', lr=0.0001, lr_step=[5], ltrb=False, master_batch_size=2, mean=None, metric='loss', min_box_area=100, move_px=0, mse_loss=False, multi_loss='uncertainty', nID_dict=defaultdict(<class 'int'>, {0: 1361, 1: 1343}), new_overlap_thres=0.7, no_aug_hsv=True, norm_wh=False, not_cuda_benchmark=False, not_prefetch_test=False, not_reg_offset=False, num_classes=2, num_epochs=10, num_iters=-1, num_stacks=1, num_workers=8, off_weight=1, output_format='video', output_h=152, output_name='test', output_root='../demos', output_w=272, pad=31, print_iter=0, proportion_iou=0.5, reg_loss='l1', reg_offset=True, reid_cls_ids=[0, 1], reid_cls_names='lemur,box', reid_dim=128, resume=False, root_dir='/content/PriMAT-tracking/src/lib/../..', save_all=True, save_dir='/content/PriMAT-tracking/src/lib/../../exp/mot/colab_test', seed=13, sim_thres=0.8, squared_bboxes=False, std=None, store_opt=True, task='mot', tb_dir='/content/PriMAT-tracking/src/lib/../../exp/mot/colab_test/tensor_board', test=False, track_buffer=3, train_only_gc=False, trainval=False, use_buffered_iou=False, use_gc=False, val_intervals=10, vis_thresh=0.5, wh_weight=0.1, zoom_max=1, zoom_min=1)\n",
            "Creating model...\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Starting training...\n",
            "mot/colab_test |################################| train: [1][249/250]|Tot: 0:03:40 |ETA: 0:00:01 |loss 192.1227 |hm_loss 57.3105 |wh_loss 12.2753 |off_loss 0.9269 |id_loss 3.1945 |Data 0.201s(0.202s) |Net 0.881s  \n",
            "mot/colab_test |###                             | train: [2][26/250]|Tot: 0:00:25 |ETA: 0:03:10 |loss 27.6372 |hm_loss 6.3347 |wh_loss 10.7148 |off_loss 0.3216 |id_loss 3.2459 |Data 0.199s(0.259s) |Net 0.936s"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your models will be saved in exp/mot/exp_id and end with .pth."
      ],
      "metadata": {
        "id": "76ahWFSUyEfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "### Apply to videos\n",
        "\n",
        "If you want to have video output, you will need to activate ffmpeg."
      ],
      "metadata": {
        "id": "tdb8Vxcyya4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "UURjc1qhyRh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If you want the model you just trained, you can directly change the path to ../exp/mot/exp_id/model_last.pth (or any other model you want). Alternatively, we can use the pretrained lemur model from [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> Models).\n",
        "- You can upload your own videos or a validation video (e.g. Eval8.mp4) into data/Videos. Videos can be downloaded [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> ValidationVideos/lemur_videos_eval/Videos/).\n",
        "- If you set output_format to video, a video will be saved to output_root/output_name. If you set it to text, only the tracking output as a .txt file will be saved."
      ],
      "metadata": {
        "id": "gg8AQ_g30V7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install motmetrics==1.2.0\n",
        "!pip install lap==0.4.0\n",
        "!pip install cython_bbox==0.1.3"
      ],
      "metadata": {
        "id": "cNU0lI5x2HEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd src\n",
        "\n",
        "python demo.py mot  --load_tracking_model ../models/lemur_tracking.pth\\\n",
        "                    --conf_thres 0.02\\\n",
        "                    --det_thres 0.5\\\n",
        "                    --new_overlap_thres 0.8\\\n",
        "                    --sim_thres 0.8\\\n",
        "                    --input_video ../data/Videos/Eval8.mp4\\\n",
        "                    --output_root ../videos/test/\\\n",
        "                    --output_name test_video\\\n",
        "                    --store_opt\\\n",
        "                    --line_thickness 2\\\n",
        "                    --debug_info\\\n",
        "                    --arch hrnet_32\\\n",
        "                    --output_format video\\\n",
        "                    --reid_cls_names \"lemur,box\"\\\n",
        "                    --proportion_iou 0.2\\\n",
        "                    --double_kalman\n",
        "\n",
        "\n",
        "cd .."
      ],
      "metadata": {
        "id": "5T2o99sFyq7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}