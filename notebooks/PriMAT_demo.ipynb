{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PriMAT: Multi-animal tracking\n",
        "\n",
        "In this notebook, we want to demonstrate how to train a tracking model from a few hundred frames. We will train a model that is able to track lemurs and feeding boxes with labelled images which can be downloaded [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> Training Images / LemurBoxSep22 )."
      ],
      "metadata": {
        "id": "A0Atdc4Fr6C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!python3 --version"
      ],
      "metadata": {
        "id": "mY2JvaUBk8ai",
        "outputId": "bae44cb1-d04b-47c6-a25a-5193d37214bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 10 23:32:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Python 3.8.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
        "!pip install yacs==0.1.8\n",
        "!pip install opencv-python\n",
        "!pip install progress==1.6\n",
        "!pip install scikit-learn==1.2.2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SrxawMA3lDGn",
        "outputId": "a59dfc0e-dcba-4aa2-b179-e15fbf5ee933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cu118.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.8/dist-packages (2.1.2+pt21cu118)\n",
            "Requirement already satisfied: yacs==0.1.8 in /usr/local/lib/python3.8/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from yacs==0.1.8) (6.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: progress==1.6 in /usr/local/lib/python3.8/dist-packages (1.6)\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.8/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hj9s06hC5_Yq",
        "outputId": "3d5ce11a-e203-4c64-f359-4bf2df54a87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PriMAT-tracking'...\n",
            "remote: Enumerating objects: 8971, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 8971 (delta 0), reused 0 (delta 0), pack-reused 8968 (from 2)\u001b[K\n",
            "Receiving objects: 100% (8971/8971), 144.93 MiB | 33.79 MiB/s, done.\n",
            "Resolving deltas: 100% (1789/1789), done.\n",
            "Updating files: 100% (8972/8972), done.\n",
            "/content/PriMAT-tracking\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ecker-lab/PriMAT-tracking.git\n",
        "%cd PriMAT-tracking/\n",
        "!mkdir data\n",
        "!mkdir models\n",
        "!mkdir exp\n",
        "!mkdir videos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "### Extract data"
      ],
      "metadata": {
        "id": "AE-cGOn0x53f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have to upload the folder with the data to the colab space on the left. I uploaded it as a tar file and extracted it into the folder \"data\". The only important thing is that after this step you have training material in the folder data."
      ],
      "metadata": {
        "id": "dRfHHdpsslRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WbTCdH-fx_WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data\n",
        "!tar -xvf ../../LemurBoxSep22.zip >/dev/null!tar\n",
        "%cd .."
      ],
      "metadata": {
        "id": "ix7jA_T4CL62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run training script"
      ],
      "metadata": {
        "id": "2Z6s9wDSyA_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cell you start the training. Before this you have to make sure a few things:\n",
        "- The data_cfg file has to point to the correct location of your data. Open it (it is in PriMAT-tracking/src/lib/cfg/lemur-box.json) and adapt the root (for me it is /content/PriMAT-tracking/data/ in colab).\n",
        "- Give your experiment a name (--exp_id) so that you can find the model afterwards in exp/mot/exp_id/."
      ],
      "metadata": {
        "id": "eZF9kulKs868"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "cd src\n",
        "python train.py mot --exp_id colab_test\\\n",
        "                    --load_model ''\\\n",
        "                    --num_epochs 10\\\n",
        "                    --lr_step 5\\\n",
        "                    --lr '1e-4'\\\n",
        "                    --data_cfg '../src/lib/cfg/lemur_box.json'\\\n",
        "                    --store_opt\\\n",
        "                    --arch hrnet_32\\\n",
        "                    --gpus 0\\\n",
        "                    --batch_size 2\\\n",
        "                    --seed 13\\\n",
        "                    --reid_cls_names lemur,box\\\n",
        "                    --val_intervals 10\\\n",
        "                    --save_all\n",
        "cd .."
      ],
      "metadata": {
        "id": "06vNX0r2EQFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your models will be saved in exp/mot/exp_id and end with .pth."
      ],
      "metadata": {
        "id": "76ahWFSUyEfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n",
        "\n",
        "### Apply to videos\n",
        "\n",
        "If you want to have video output, you will need to activate ffmpeg."
      ],
      "metadata": {
        "id": "tdb8Vxcyya4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "UURjc1qhyRh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If you want the model you just trained, you can directly change the path to ../exp/mot/exp_id/model_last.pth (or any other model you want). Alternatively, we can use the pretrained lemur model from [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> Models).\n",
        "- You can upload your own videos or a validation video (e.g. Eval8.mp4) into data/Videos. Videos can be downloaded [here](https://owncloud.gwdg.de/index.php/s/Mq4m9k1B74cN6ys) (-> ValidationVideos/lemur_videos_eval/Videos/).\n",
        "- If you set output_format to video, a video will be saved to output_root/output_name. If you set it to text, only the tracking output as a .txt file will be saved."
      ],
      "metadata": {
        "id": "gg8AQ_g30V7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install motmetrics==1.2.0\n",
        "!pip install lap==0.4.0\n",
        "!pip install cython_bbox==0.1.3"
      ],
      "metadata": {
        "id": "cNU0lI5x2HEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "cd src\n",
        "\n",
        "python demo.py mot  --load_tracking_model ../models/lemur_tracking.pth\\\n",
        "                    --conf_thres 0.02\\\n",
        "                    --det_thres 0.5\\\n",
        "                    --new_overlap_thres 0.8\\\n",
        "                    --sim_thres 0.8\\\n",
        "                    --input_video ../data/Videos/Eval8.mp4\\\n",
        "                    --output_root ../videos/test/\\\n",
        "                    --output_name test_video\\\n",
        "                    --store_opt\\\n",
        "                    --line_thickness 2\\\n",
        "                    --debug_info\\\n",
        "                    --arch hrnet_32\\\n",
        "                    --output_format video\\\n",
        "                    --reid_cls_names \"lemur,box\"\\\n",
        "                    --proportion_iou 0.2\\\n",
        "                    --double_kalman\n",
        "\n",
        "\n",
        "cd .."
      ],
      "metadata": {
        "id": "5T2o99sFyq7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}